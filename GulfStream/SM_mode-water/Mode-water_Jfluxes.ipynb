{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we show the code for analysis.\n",
    "\n",
    "We would like to reconstruct Fig. 12 in [Wenegrat et al. (2018)](https://journals.ametsoc.org/doi/full/10.1175/JPO-D-17-0219.1) to see the relative importance of surface forcing on mode water formation in our submesoscale permitting North Atlantic simulation with tidal forcing (eNATL60). The spatial resolution is 1/60$^\\circ$ with 300 vertical layers allowing for well resolved eddies. The sea-surface data from a run without tidal forcing are available on [Pangeo](https://catalog.pangeo.io/browse/master/ocean/MEOM_NEMO/).\n",
    "\n",
    "The contributions due to turbulent thermal wind ($J_\\text{TTW}$), surface wind kinematic forcing ($J_\\text{wind}$) and buoyancy forcing ($J^\\text{buoy}_\\text{D}$) are diagnosed as: \n",
    "$$J_\\text{TTW} \\simeq -0.05H_\\text{ML}|\\overline{\\nabla_\\text{h}b}^z|^2,$$\n",
    "\n",
    "$$J_\\text{wind} \\simeq f\\frac{\\text{EBF}}{H_\\text{ML}} = \\frac{({\\bf \\tau}^w\\times {\\bf k})\\cdot \\overline{\\nabla_\\text{h}b}^z}{\\rho H_\\text{ML}} = \\frac{\\tau^y\\overline{b_x}^z - \\tau^x\\overline{b_y}^z}{\\rho H_\\text{ML}}$$\n",
    "where $\\text{EBF} = \\frac{1}{\\rho f}({\\bf \\tau}^w\\times {\\bf k})\\cdot\\overline{\\nabla_\\text{h}b}^z$ is the Ekman buoyancy flux, and\n",
    "$$J^\\text{buoy}_\\text{D} \\simeq f c_s \\frac{B_0}{H_\\text{ML}}$$\n",
    "where $c_s = 1.2$ comes from the assumption that that the turbulent vertical buoyancy flux divergence will remain similar, in some area-integrated sense, to classic upright convection ([Wenegrat et al., 2018](https://journals.ametsoc.org/doi/full/10.1175/JPO-D-17-0219.1)).\n",
    "The surface buoyancy flux is ([Buckingham et al., 2019](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2019MS001801)):\n",
    "$$B_0 = \\alpha g\\frac{Q_0}{\\rho_0 c_p} + \\beta g (E-P) S_0$$\n",
    "where $Q_0, E-P$ and $S_0$ are the surface net heat, fresh-water flux and salinity respectively. \n",
    "\n",
    "The fluxes are integrated in time only when and where the mode-water isopycnal outcrops at the surface. \n",
    "For simplicity and with prior knowledge that density is temperature dominated in the Gulf Stream region, we will define the mode water as waters with $18 \\pm 1 ^\\circ\\text{C}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/cnt0024/hmg2840/tuchida/condapack/lib/python3.7/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Failed to start diagnostics server on port 8787. [Errno 13] Permission denied\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37182</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:43250/status' target='_blank'>http://127.0.0.1:43250/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>12</li>\n",
       "  <li><b>Cores: </b>84</li>\n",
       "  <li><b>Memory: </b>405.28 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:37182' processes=12 threads=84, memory=405.28 GB>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "\n",
    "###################################\n",
    "# We start an interactive session with 12 dask workers.\n",
    "# The power of dask is that setting up a cluster for parallel computation\n",
    "# is mostly done in this cell, which allows us to focus on the science.\n",
    "###################################\n",
    "cluster = LocalCluster()\n",
    "cluster.scale(12)\n",
    "\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import xscale\n",
    "import gsw\n",
    "import os.path as op\n",
    "from xhistogram.xarray import histogram as xhist\n",
    "\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddir = '/store/CT1/hmg2840/lbrodeau/eNATL60/eNATL60-BLBT02-S/'\n",
    "xtra = '/store/CT1/hmg2840/lbrodeau/eNATL60/eNATL60-BLBT02X-S'\n",
    "scratch = '/scratch/cnt0024/hmg2840/tuchida/temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys,ye,xs,xe = (1400,2800,950,2550)\n",
    "g = 9.81\n",
    "cp = 4e3\n",
    "cs = 1.2\n",
    "zchunk = 10\n",
    "xchunk = -1\n",
    "ychunk = -1\n",
    "tchunk = -1\n",
    "\n",
    "gdepw = xr.open_dataset(op.join(scratch,'gdepw_eNATL60.nc')\n",
    "                       ).gdepw.sel(y=slice(ys,ye),x=slice(xs,xe)\n",
    "                                  ).chunk({'y':ychunk,'x':xchunk})\n",
    "dsmask = xr.open_dataset(op.join(ddir,'../eNATL60-I/mesh_mask_eNATL60_3.6.nc'), \n",
    "                         chunks={'z':zchunk,'y':ychunk,'x':xchunk}\n",
    "                        ).isel(y=slice(ys,ye),x=slice(xs,xe)).isel(t=0)\n",
    "f = xr.apply_ufunc(gsw.f, dsmask.nav_lat, dask='parallelized', output_dtypes=[float,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29] 1393201\n"
     ]
    }
   ],
   "source": [
    "# days = np.concatenate((np.arange(12,32,dtype=int), np.arange(1,6,dtype=int)))\n",
    "days = np.arange(6,30, dtype=int)\n",
    "dirs = 1393201\n",
    "print(days,dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We iterate over each daily file, which stores 24 timesteps of hourly averaged data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 10-27\n",
      "Day: 10-28\n",
      "Day: 10-29\n"
     ]
    }
   ],
   "source": [
    "month = 10\n",
    "year = 2010\n",
    "istart = -3\n",
    "\n",
    "for i in days[istart:]:\n",
    "    j = month\n",
    "    l = j\n",
    "    m = month+0\n",
    "    \n",
    "    if i < days[0]:\n",
    "        l = m\n",
    "            \n",
    "###################################\n",
    "# We open the files necessary for analysis.\n",
    "# The files are chunked along each dimension where dask automatically\n",
    "# executes the computation on each chunk in parallel.\n",
    "# At this point, no data is loaded onto memory yet and \n",
    "# they are symbolic stake holders up until they are called upon to compute.\n",
    "###################################\n",
    "    dsT = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_gridT_%4d%02d%02d-%4d%02d%02d.nc' \n",
    "                                  % (dirs,int(dirs+10800*len(days)*.2-1),\n",
    "                                     year,j,days[0],year,m,days[-1],\n",
    "                                     year,l,i,year,l,i)),\n",
    "                          chunks={'time_counter':tchunk,'deptht':zchunk,'y':ychunk,'x':xchunk}\n",
    "                         ).sel(deptht=slice(None,810))\n",
    "    dsS = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_gridS_%4d%02d%02d-%4d%02d%02d.nc' \n",
    "                                  % (dirs,int(dirs+10800*len(days)*.2-1),\n",
    "                                     year,j,days[0],year,m,days[-1],\n",
    "                                     year,l,i,year,l,i)),\n",
    "                          chunks={'time_counter':tchunk,'deptht':zchunk,'y':ychunk,'x':xchunk}\n",
    "                         ).sel(deptht=slice(None,810))\n",
    "    dsflx = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_flxT_%4d%02d%02d-%4d%02d%02d.nc'\n",
    "                                    % (dirs,int(dirs+10800*len(days)*.2-1),\n",
    "                                       year,j,days[0],year,m,days[-1],\n",
    "                                       year,l,i,year,l,i)),\n",
    "                            chunks={'time_counter':tchunk,'y':ychunk,'x':xchunk}\n",
    "                           )\n",
    "    dsH = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_gridT-2D_%4d%02d%02d-%4d%02d%02d.nc' \n",
    "                                  % (dirs,int(dirs+10800*len(days)*.2-1),\n",
    "                                     year,j,days[0],year,m,days[-1],\n",
    "                                     year,l,i,year,l,i)),\n",
    "                          chunks={'time_counter':tchunk,'y':ychunk,'x':xchunk}\n",
    "                         )\n",
    "    dsx = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_gridU-2D_%4d%02d%02d-%4d%02d%02d.nc' \n",
    "                                  % (dirs,int(dirs+10800*len(days)*.2-1),\n",
    "                                     year,j,days[0],year,m,days[-1],\n",
    "                                     year,l,i,year,l,i)),\n",
    "                          chunks={'time_counter':tchunk,'y':ychunk,'x':xchunk}\n",
    "                         )\n",
    "    dsy = xr.open_dataset(op.join(xtra,'%08d-%08d/eNATL60-BLBT02X_1h_%4d%02d%02d_%4d%02d%02d_gridV-2D_%4d%02d%02d-%4d%02d%02d.nc' \n",
    "                                  % (dirs,int(dirs+10800*len(days)*.2-1),\n",
    "                                     year,j,days[0],year,m,days[-1],\n",
    "                                     year,l,i,year,l,i)),\n",
    "                          chunks={'time_counter':tchunk,'y':ychunk,'x':xchunk}\n",
    "                         )\n",
    "        \n",
    "        \n",
    "    if i == days[istart]:\n",
    "        maskT = dsmask.tmask.isel(z=slice(None,len(dsT.deptht)))\n",
    "        maskU = dsmask.umask.isel(z=0)\n",
    "        maskV = dsmask.vmask.isel(z=0)\n",
    "        \n",
    "    for tt in range(len(dsflx.time_counter)):\n",
    "        CT = dsT.votemper.isel(y=slice(ys,ye),\n",
    "                               x=slice(xs,xe)).isel(time_counter=tt).where(xr.DataArray(maskT.data, \n",
    "                                                                                        dims=['deptht','y','x']) != 0.)\n",
    "        SA = dsS.vosaline.isel(y=slice(ys,ye),\n",
    "                               x=slice(xs,xe)).isel(time_counter=tt).where(xr.DataArray(maskT.data, \n",
    "                                                                                        dims=['deptht','y','x']) != 0.)\n",
    "        ssh = dsH.sossheig.isel(y=slice(ys,ye),\n",
    "                                x=slice(xs,xe)).isel(time_counter=tt).where(xr.DataArray(maskT.isel(z=0).data, \n",
    "                                                                                         dims=['y','x']) != 0.)\n",
    "        taux = dsx.sozotaux.isel(y=slice(ys,ye),\n",
    "                                 x=slice(xs,xe)).isel(time_counter=tt).where(xr.DataArray(maskU.data, \n",
    "                                                                                          dims=['y','x']) != 0.)\n",
    "        tauy = dsy.sometauy.isel(y=slice(ys,ye),\n",
    "                                 x=slice(xs,xe)).isel(time_counter=tt).where(xr.DataArray(maskV.data, \n",
    "                                                                                          dims=['y','x']) != 0.)\n",
    "\n",
    "###################################\n",
    "# We compute in parallel the potential density (sig0), mixed-layer depth (MLD),\n",
    "# surface buoyancy forcing (Bo), and the MLD averaged horizontal gradients of buoyancy.\n",
    "# Data is still not loaded into memory.\n",
    "###################################\n",
    "        sig0 = xr.apply_ufunc(gsw.sigma0, SA, CT, \n",
    "                              dask='parallelized', output_dtypes=[float,])\n",
    "        buoy = -g*sig0*1e-3\n",
    "        z10 = 6\n",
    "        nMLD = z10 + np.abs((sig0.isel(deptht=slice(z10,None)).fillna(999.)\n",
    "                             - sig0.isel(deptht=z10).fillna(999.)\n",
    "                            ) - 0.03).argmin(dim='deptht',skipna=True)\n",
    "        e3w = dsmask.e3w_0 * (1+ssh*gdepw**-1)\n",
    "        e3t = dsmask.e3t_0 * (1+ssh*gdepw**-1)\n",
    "\n",
    "        MLD = e3t.fillna(0.).where(e3t.z <= nMLD.fillna(0.).compute()\n",
    "                                  ).sum('z',skipna=True)\n",
    "\n",
    "        alpha = xr.apply_ufunc(gsw.alpha, SA.isel(deptht=0), CT.isel(deptht=0), 0.,\n",
    "                               dask='parallelized', output_dtypes=['float',])\n",
    "        beta = xr.apply_ufunc(gsw.beta, SA.isel(deptht=0), CT.isel(deptht=0), 0.,\n",
    "                              dask='parallelized', output_dtypes=['float',])\n",
    "        Bo = g*(-alpha * dsflx.qt_oce.isel(time_counter=tt).isel(y=slice(ys,ye),x=slice(xs,xe)) \n",
    "                * ((sig0.isel(deptht=0)+1e3)*cp)**-1\n",
    "                + beta * dsflx.sowaflup.isel(time_counter=tt).isel(y=slice(ys,ye),x=slice(xs,xe))\n",
    "                  * SA.isel(deptht=0)\n",
    "               )    # Positive values defined as destablizing conditions\n",
    "        \n",
    "        bx = (buoy.isel(x=slice(1,None))\n",
    "              + buoy.isel(x=slice(None,-1)).data\n",
    "             ) * .5\n",
    "        by = (buoy.isel(y=slice(1,None))\n",
    "              + buoy.isel(y=slice(None,-1)).data\n",
    "             ) * .5\n",
    "        dbx = bx.diff(dim='x') * dsmask.e1u.isel(x=slice(1,-1))**-1\n",
    "        dby = by.diff(dim='y') * dsmask.e2v.isel(y=slice(1,-1))**-1\n",
    "\n",
    "\n",
    "        dbx = (dbx.fillna(0.) * xr.DataArray(e3t.isel(z=slice(len(dsT.deptht))).isel(x=slice(1,-1)).data,\n",
    "                                             dims=['deptht','y','x'])\n",
    "              ).where(dbx.deptht <= MLD.isel(x=slice(1,-1))\n",
    "                     ).sum('deptht',skipna=True) * MLD.isel(x=slice(1,-1))**-1\n",
    "        dby = (dby.fillna(0.) * xr.DataArray(e3t.isel(z=slice(len(dsT.deptht))).isel(y=slice(1,-1)).data,\n",
    "                                             dims=['deptht','y','x'])\n",
    "              ).where(dby.deptht <= MLD.isel(y=slice(1,-1))\n",
    "                     ).sum('deptht',skipna=True) * MLD.isel(y=slice(1,-1))**-1\n",
    "        db2 = dbx.isel(y=slice(1,-1))**2 + dby.isel(x=slice(1,-1))**2\n",
    "\n",
    "\n",
    "###################################\n",
    "# With the command .load() and .compute(), the data are loaded for the first time into memory.\n",
    "# The \"J\" fluxes are computed and saved below.\n",
    "###################################\n",
    "        sst = CT.isel(deptht=0).load()\n",
    "\n",
    "        if tt == 0:\n",
    "            J_d = (Bo*f*cs*MLD**-1).compute().where(sst<19).where(sst>17)\n",
    "            J_ttw = -0.05*(MLD.isel(y=slice(1,-1),x=slice(1,-1)) * db2\n",
    "                          ).compute().where(sst.isel(y=slice(1,-1),x=slice(1,-1))<19\n",
    "                                           ).where(sst.isel(y=slice(1,-1),x=slice(1,-1))>17)\n",
    "            J_wind = ((.5*(tauy.isel(y=slice(1,None))+tauy.isel(y=slice(None,-1))).isel(y=slice(1,None),x=slice(1,-1)) \n",
    "                       * dbx.isel(y=slice(1,-1)) \n",
    "                       - .5*(taux.isel(x=slice(1,None))+taux.isel(x=slice(None,-1))).isel(y=slice(1,-1),x=slice(1,None)) \n",
    "                         * dby.isel(x=slice(1,-1))\n",
    "                      ) * ((sig0.fillna(0.)+1e3) * xr.DataArray(e3t[:len(dsT.deptht)].fillna(0.).data, \n",
    "                                                                dims=['deptht','y','x']\n",
    "                                                               )\n",
    "                          ).where(sig0.deptht <= MLD).isel(y=slice(1,-1),x=slice(1,-1)).sum('deptht',skipna=True)**-1\n",
    "                     ).compute().where(sst.isel(y=slice(1,-1),x=slice(1,-1))<19\n",
    "                                      ).where(sst.isel(y=slice(1,-1),x=slice(1,-1))>17)\n",
    "        else:\n",
    "            J_d = xr.concat([J_d, (Bo*f*cs*MLD**-1).compute().where(sst<19).where(sst>17)], \n",
    "                            'time_counter')\n",
    "            J_ttw = xr.concat([J_ttw, -0.05*(MLD.isel(y=slice(1,-1),x=slice(1,-1)) * db2\n",
    "                                            ).compute().where(sst.isel(y=slice(1,-1),x=slice(1,-1))<19\n",
    "                                                             ).where(sst.isel(y=slice(1,-1),x=slice(1,-1))>17)],\n",
    "                              'time_counter')\n",
    "            J_wind = xr.concat([J_wind, ((.5*(tauy.isel(y=slice(1,None))+tauy.isel(y=slice(None,-1))).isel(y=slice(1,None),\n",
    "                                                                                                           x=slice(1,-1)) \n",
    "                                          * dbx.isel(y=slice(1,-1)) \n",
    "                                          - .5*(taux.isel(x=slice(1,None))+taux.isel(x=slice(None,-1))).isel(y=slice(1,-1),\n",
    "                                                                                                             x=slice(1,None)) \n",
    "                                          * dby.isel(x=slice(1,-1))\n",
    "                                         ) * ((sig0.fillna(0.)+1e3) * xr.DataArray(e3t[:len(dsT.deptht)].fillna(0.).data, \n",
    "                                                                                   dims=['deptht','y','x']\n",
    "                                                                                  )\n",
    "                                             ).where(sig0.deptht <= MLD).isel(y=slice(1,-1),\n",
    "                                                                              x=slice(1,-1)).sum('deptht',skipna=True)**-1\n",
    "                                        ).compute().where(sst.isel(y=slice(1,-1),x=slice(1,-1))<19\n",
    "                                                         ).where(sst.isel(y=slice(1,-1),x=slice(1,-1))>17)],\n",
    "                                'time_counter')\n",
    "        \n",
    "        \n",
    "    dsT.close()\n",
    "    dsS.close()\n",
    "    dsH.close()\n",
    "    dsflx.close()\n",
    "    dsx.close()\n",
    "    dsy.close() \n",
    "    \n",
    "###################################\n",
    "# The \"J\" fluxes are saved as netcdf files.\n",
    "###################################\n",
    "    dsave = J_d.isel(y=slice(1,-1),x=slice(1,-1)).drop_vars('time_centered').to_dataset(name='J_D')\n",
    "    dsave['J_TTW'] = J_ttw.drop_vars('time_centered')\n",
    "    dsave['J_wind'] = J_wind.drop_vars('time_centered')\n",
    "    dsave.to_netcdf(op.join(scratch,'GulfStream/Jflux_%4d-%02d-%02d.nc' \n",
    "                                % (year,l,i)))\n",
    "    dsave.close()\n",
    "    print(r\"Day: %02d-%02d\" % (l,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
